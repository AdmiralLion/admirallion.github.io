{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35cde9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134217728"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd #for manipulating the csv data\n",
    "import numpy as np #for mathematical calculation\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import sys, threading\n",
    "sys.setrecursionlimit(10**7) # max depth of recursion\n",
    "threading.stack_size(2**27)  # new thread will get stack of such size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b0777fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from xml.dom import minidom\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_array, check_is_fitted, check_X_y\n",
    "\n",
    "\n",
    "class C45(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, attrNames=None):\n",
    "        if attrNames is not None:\n",
    "            attrNames = [''.join(i for i in x if i.isalnum()).replace(' ', '_') for x in attrNames]\n",
    "        self.attrNames = attrNames\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        self.resultType = type(y[0])\n",
    "        if self.attrNames is None:\n",
    "            self.attrNames = [f'attr{x}' for x in range(len(self.X_[0]))]\n",
    "\n",
    "        assert(len(self.attrNames) == len(self.X_[0]))\n",
    "\n",
    "        data = [[] for i in range(len(self.attrNames))]\n",
    "        categories = []\n",
    "\n",
    "        for i in range(len(self.X_)):\n",
    "            categories.append(str(self.y_[i]))\n",
    "            for j in range(len(self.attrNames)):\n",
    "                data[j].append(self.X_[i][j])\n",
    "        root = ET.Element('DecisionTree')\n",
    "        grow_tree(data,categories,root,self.attrNames)\n",
    "        self.tree_ = ET.tostring(root, encoding=\"unicode\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, ['tree_', 'resultType', 'attrNames'])\n",
    "        X = check_array(X)\n",
    "        dom = minidom.parseString(self.tree_)\n",
    "        root = dom.childNodes[0]\n",
    "        prediction = []\n",
    "        for i in range(len(X)):\n",
    "            answerlist = decision(root,X[i],self.attrNames,1)\n",
    "            answerlist = sorted(answerlist.items(), key=lambda x:x[1], reverse = True )\n",
    "            answer = answerlist[0][0]\n",
    "            prediction.append((self.resultType)(answer))\n",
    "        return prediction\n",
    "\n",
    "    def printTree(self):\n",
    "        check_is_fitted(self, ['tree_'])\n",
    "        dom = minidom.parseString(self.tree_)\n",
    "        print(dom.toprettyxml(newl=\"\\r\\n\"))\n",
    "import math\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "\n",
    "def prettify(elem, level=0):\n",
    "    i = \"\\n\" + level*\"  \"\n",
    "    if len(elem):\n",
    "        if not elem.text or not elem.text.strip():\n",
    "            elem.text = i + \"  \"\n",
    "        for e in elem:\n",
    "            prettify(e, level+1)\n",
    "        if not e.tail or not e.tail.strip():\n",
    "            e.tail = i\n",
    "    if level and (not elem.tail or not elem.tail.strip()):\n",
    "        elem.tail = i\n",
    "    return elem\n",
    "\n",
    "def isnum(attr):\n",
    "    for x in set(attr):\n",
    "        if not x==\"?\":\n",
    "            try:\n",
    "                x=float(x)\n",
    "                return isinstance(x,float)\n",
    "            except ValueError:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def entropy(x):\n",
    "    ent=0\n",
    "    for k in set(x):\n",
    "        p_i=float(x.count(k))/len(x)\n",
    "        ent=ent-p_i* math.log(p_i,2)\n",
    "    return ent\n",
    "\n",
    "def gain_ratio(category,attr):\n",
    "    s=0\n",
    "    cat=[]\n",
    "    att=[]\n",
    "    for i in range(len(attr)):\n",
    "        if not attr[i]==\"?\":\n",
    "            cat.append(category[i])\n",
    "            att.append(attr[i])\n",
    "    for i in set(att):      \n",
    "        p_i=float(att.count(i))/len(att)\n",
    "        cat_i=[]\n",
    "        for j in range(len(cat)):\n",
    "            if att[j]==i:\n",
    "                cat_i.append(cat[j])\n",
    "        s=s+p_i*entropy(cat_i)\n",
    "    gain=entropy(cat)-s\n",
    "    ent_att=entropy(att)\n",
    "    if ent_att==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return gain/ent_att\n",
    "\n",
    "def gain(category,attr):\n",
    "    cats=[]\n",
    "    for i in range(len(attr)):\n",
    "        if not attr[i]==\"?\":\n",
    "            cats.append([float(attr[i]),category[i]])\n",
    "    cats=sorted(cats, key=lambda x:x[0])\n",
    "    \n",
    "    cat=[cats[i][1] for i in range(len(cats))]\n",
    "    att=[cats[i][0] for i in range(len(cats))]\n",
    "    if len(set(att))==1:\n",
    "        return 0\n",
    "    else:\n",
    "        gains=[]\n",
    "        div_point=[]\n",
    "        for i in range(1,len(cat)):\n",
    "            if not att[i]==att[i-1]:\n",
    "                gains.append(entropy(cat[:i])*float(i)/len(cat)+entropy(cat[i:])*(1-float(i)/len(cat)))\n",
    "                div_point.append(i)\n",
    "        gain=entropy(cat)-min(gains)\n",
    "    \n",
    "        p_1=float(div_point[gains.index(min(gains))])/len(cat)\n",
    "        ent_attr= -p_1*math.log(p_1,2)-(1-p_1)*math.log((1-p_1),2)\n",
    "        return gain/ent_attr\n",
    "\n",
    "def division_point(category,attr):\n",
    "    cats=[]\n",
    "    for i in range(len(attr)):\n",
    "        if not attr[i]==\"?\":\n",
    "            cats.append([float(attr[i]),category[i]])\n",
    "    cats=sorted(cats, key=lambda x:x[0])\n",
    "    \n",
    "    cat=[cats[i][1] for i in range(len(cats))]\n",
    "    att=[cats[i][0] for i in range(len(cats))]\n",
    "    gains=[]\n",
    "    div_point=[]\n",
    "    for i in range(1,len(cat)):\n",
    "        if not att[i]==att[i-1]:\n",
    "            gains.append(entropy(cat[:i])*float(i)/len(cat)+entropy(cat[i:])*(1-float(i)/len(cat)))\n",
    "            div_point.append(i)\n",
    "    return att[div_point[gains.index(min(gains))]]\n",
    "\n",
    "def grow_tree(data,category,parent,attrs_names):\n",
    "    if len(set(category))>1:\n",
    "        \n",
    "        division=[]\n",
    "        for i in range(len(data)):\n",
    "            if set(data[i])==set(\"?\"):\n",
    "                division.append(0)\n",
    "            else:\n",
    "                if (isnum(data[i])):\n",
    "                    division.append(gain(category,data[i]))           \n",
    "                else:\n",
    "                    division.append(gain_ratio(category,data[i]))\n",
    "        if max(division)==0:\n",
    "            num_max=0\n",
    "            for cat in set(category):\n",
    "                num_cat=category.count(cat)\n",
    "                if num_cat>num_max:\n",
    "                    num_max=num_cat\n",
    "                    most_cat=cat                \n",
    "            parent.text=most_cat\n",
    "        else:\n",
    "            index_selected=division.index(max(division))\n",
    "            name_selected=str(attrs_names[index_selected])\n",
    "            if isnum(data[index_selected]):\n",
    "                div_point=division_point(category,data[index_selected])\n",
    "                r_son_data=[[] for i in range(len(data))]\n",
    "                r_son_category=[]\n",
    "                l_son_data=[[] for i in range(len(data))]\n",
    "                l_son_category=[]\n",
    "                for i in range(len(category)):\n",
    "                    if not data[index_selected][i]==\"?\":\n",
    "                        if float(data[index_selected][i])<float(div_point):\n",
    "                            l_son_category.append(category[i])\n",
    "                            for j in range(len(data)):\n",
    "                                l_son_data[j].append(data[j][i])     \n",
    "                        else:\n",
    "                            r_son_category.append(category[i])\n",
    "                            for j in range(len(data)):\n",
    "                                r_son_data[j].append(data[j][i])  \n",
    "                if len(l_son_category)>0 and len(r_son_category)>0:\n",
    "                    p_l=float(len(l_son_category))/(len(data[index_selected])-data[index_selected].count(\"?\"))\n",
    "                    son=ET.SubElement(parent,name_selected,{'value':str(div_point),\"flag\":\"l\",\"p\":str(round(p_l,3))})\n",
    "                    grow_tree(l_son_data,l_son_category,son,attrs_names)\n",
    "                    son=ET.SubElement(parent,name_selected,{'value':str(div_point),\"flag\":\"r\",\"p\":str(round(1-p_l,3))})\n",
    "                    grow_tree(r_son_data,r_son_category,son,attrs_names)\n",
    "                else:\n",
    "                    num_max=0\n",
    "                    for cat in set(category):\n",
    "                        num_cat=category.count(cat)\n",
    "                        if num_cat>num_max:\n",
    "                            num_max=num_cat\n",
    "                            most_cat=cat                \n",
    "                    parent.text=most_cat\n",
    "            else:\n",
    "                for k in set(data[index_selected]):\n",
    "                    if not k==\"?\":\n",
    "                        son_data=[[] for i in range(len(data))]\n",
    "                        son_category=[]\n",
    "                        for i in range(len(category)):\n",
    "                            if data[index_selected][i]==k:\n",
    "                                son_category.append(category[i])\n",
    "                                for j in range(len(data)):\n",
    "                                    son_data[j].append(data[j][i])\n",
    "                        son=ET.SubElement(parent,name_selected,{'value':k,\"flag\":\"m\",'p':str(round(float(len(son_category))/(len(data[index_selected])-data[index_selected].count(\"?\")),3))}) \n",
    "                        grow_tree(son_data,son_category,son,attrs_names)   \n",
    "    else:\n",
    "        parent.text=category[0]\n",
    "\n",
    "def add(d1,d2):\n",
    "    d=d1\n",
    "    for i in d2:\n",
    "        if d.has_key(i):\n",
    "            d[i]=d[i]+d2[i]\n",
    "        else:\n",
    "            d[i]=d2[i]\n",
    "    return d\n",
    "\n",
    "def decision(root,obs,attrs_names,p):\n",
    "    if root.hasChildNodes():\n",
    "        att_name=root.firstChild.nodeName\n",
    "        if att_name==\"#text\":\n",
    "            \n",
    "            return decision(root.firstChild,obs,attrs_names,p)  \n",
    "        else:\n",
    "            att=obs[attrs_names.index(att_name)]\n",
    "            if att==\"?\":\n",
    "                d={}\n",
    "                for child in root.childNodes:                    \n",
    "                    d=add(d,decision(child,obs,attrs_names,p*float(child.getAttribute(\"p\"))))\n",
    "                return d\n",
    "            else:\n",
    "                for child in root.childNodes:\n",
    "                    if child.getAttribute(\"flag\")==\"m\" and child.getAttribute(\"value\")==att or \\\n",
    "                        child.getAttribute(\"flag\")==\"l\" and float(att)<float(child.getAttribute(\"value\")) or \\\n",
    "                        child.getAttribute(\"flag\")==\"r\" and float(att)>=float(child.getAttribute(\"value\")):\n",
    "                        return decision(child,obs,attrs_names,p)    \n",
    "    else:\n",
    "        return {root.nodeValue:p}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5950c320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      gender  age  hypertension  heart_disease ever_married      work_type  \\\n",
      "0       Male   42             0              1          Yes        Private   \n",
      "1     Female   42             0              0          Yes  Self-employed   \n",
      "2       Male   42             0              1          Yes        Private   \n",
      "3     Female   42             0              0          Yes        Private   \n",
      "4     Female   42             1              0          Yes  Self-employed   \n",
      "...      ...  ...           ...            ...          ...            ...   \n",
      "5105  Female   42             1              0          Yes        Private   \n",
      "5106  Female   42             0              0          Yes  Self-employed   \n",
      "5107  Female   40             0              0          Yes  Self-employed   \n",
      "5108    Male   42             0              0          Yes        Private   \n",
      "5109  Female   42             0              0          Yes       Govt_job   \n",
      "\n",
      "     Residence_type  bmi  avg_glucose_level   smoking_status  stroke  \n",
      "0             Urban   52                162  formerly smoked       1  \n",
      "1             Rural   52                162     never smoked       1  \n",
      "2             Rural   52                164     never smoked       1  \n",
      "3             Urban   52                162           smokes       1  \n",
      "4             Rural   52                162     never smoked       1  \n",
      "...             ...  ...                ...              ...     ...  \n",
      "5105          Urban   52                162     never smoked       0  \n",
      "5106          Urban   52                164     never smoked       0  \n",
      "5107          Rural   52                162     never smoked       0  \n",
      "5108          Rural   52                162  formerly smoked       0  \n",
      "5109          Urban   52                162          Unknown       0  \n",
      "\n",
      "[5110 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "train_data_m = pd.read_csv(\"datadiskritfinal.csv\",delimiter=';')\n",
    "print(train_data_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7a92cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1  42   0   1   1   2   1  52 162   1]\n",
      "249\n",
      "4861\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "dataset = train_data_m\n",
    "\n",
    "le= LabelEncoder()\n",
    "codex= dataset\n",
    "codex[\"gender\"] = le.fit_transform(codex[\"gender\"])\n",
    "codex[\"ever_married\"] = le.fit_transform(codex[\"ever_married\"])\n",
    "codex[\"work_type\"] = le.fit_transform(codex[\"work_type\"])\n",
    "codex[\"Residence_type\"] = le.fit_transform(codex[\"Residence_type\"])\n",
    "codex[\"smoking_status\"] = le.fit_transform(codex[\"smoking_status\"])\n",
    "\n",
    "x_data=codex.loc[:, codex.columns != \"stroke\" ].to_numpy()\n",
    "y_data=codex[\"stroke\"].to_numpy()\n",
    "print(x_data[0])\n",
    "print(len(np.where(y_data == 1)[0]))\n",
    "print(len(np.where(y_data == 0)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3054e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69225703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      gender  age  hypertension  heart_disease  ever_married  work_type  \\\n",
      "0          1   42             0              1             1          2   \n",
      "1          0   42             0              0             1          3   \n",
      "2          1   42             0              1             1          2   \n",
      "3          0   42             0              0             1          2   \n",
      "4          0   42             1              0             1          3   \n",
      "...      ...  ...           ...            ...           ...        ...   \n",
      "5105       0   42             1              0             1          2   \n",
      "5106       0   42             0              0             1          3   \n",
      "5107       0   40             0              0             1          3   \n",
      "5108       1   42             0              0             1          2   \n",
      "5109       0   42             0              0             1          0   \n",
      "\n",
      "      Residence_type  bmi  avg_glucose_level  smoking_status  stroke  \n",
      "0                  1   52                162               1       1  \n",
      "1                  0   52                162               2       1  \n",
      "2                  0   52                164               2       1  \n",
      "3                  1   52                162               3       1  \n",
      "4                  0   52                162               2       1  \n",
      "...              ...  ...                ...             ...     ...  \n",
      "5105               1   52                162               2       0  \n",
      "5106               1   52                164               2       0  \n",
      "5107               0   52                162               2       0  \n",
      "5108               0   52                162               1       0  \n",
      "5109               1   52                162               0       0  \n",
      "\n",
      "[5110 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd150837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold ke- 1\n",
      "4599\n",
      "511\n",
      "[4375 4375]\n",
      "[1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Confusion matrix : \n",
      " [[ 14  11]\n",
      " [157 329]]\n",
      "\n",
      "True positive : 14\n",
      "False negative : 11\n",
      "False positive : 157\n",
      "True negative : 329\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.08      0.56      0.14        25\n",
      "           0       0.97      0.68      0.80       486\n",
      "\n",
      "    accuracy                           0.67       511\n",
      "   macro avg       0.52      0.62      0.47       511\n",
      "weighted avg       0.92      0.67      0.76       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 67.12  %\n",
      "Akurasi fold ini adalah : 67.12  %\n",
      "===========================================================\n",
      "===========================================================\n",
      "tanpa smote\n",
      "Confusion matrix : \n",
      " [[  1  24]\n",
      " [  5 481]]\n",
      "\n",
      "True positive : 1\n",
      "False negative : 24\n",
      "False positive : 5\n",
      "True negative : 481\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.17      0.04      0.06        25\n",
      "           0       0.95      0.99      0.97       486\n",
      "\n",
      "    accuracy                           0.94       511\n",
      "   macro avg       0.56      0.51      0.52       511\n",
      "weighted avg       0.91      0.94      0.93       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 94.32  %\n",
      "Akurasi fold ini adalah : 94.32  %\n",
      "===========================================================\n",
      "fold ke- 2\n",
      "4599\n",
      "511\n",
      "[4375 4375]\n",
      "[1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Confusion matrix : \n",
      " [[ 11  14]\n",
      " [140 346]]\n",
      "\n",
      "True positive : 11\n",
      "False negative : 14\n",
      "False positive : 140\n",
      "True negative : 346\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.07      0.44      0.12        25\n",
      "           0       0.96      0.71      0.82       486\n",
      "\n",
      "    accuracy                           0.70       511\n",
      "   macro avg       0.52      0.58      0.47       511\n",
      "weighted avg       0.92      0.70      0.78       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 69.86  %\n",
      "Akurasi fold ini adalah : 69.86  %\n",
      "===========================================================\n",
      "===========================================================\n",
      "tanpa smote\n",
      "Confusion matrix : \n",
      " [[  0  25]\n",
      " [  3 483]]\n",
      "\n",
      "True positive : 0\n",
      "False negative : 25\n",
      "False positive : 3\n",
      "True negative : 483\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        25\n",
      "           0       0.95      0.99      0.97       486\n",
      "\n",
      "    accuracy                           0.95       511\n",
      "   macro avg       0.48      0.50      0.49       511\n",
      "weighted avg       0.90      0.95      0.92       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 94.52  %\n",
      "Akurasi fold ini adalah : 94.52  %\n",
      "===========================================================\n",
      "fold ke- 3\n",
      "4599\n",
      "511\n",
      "[4375 4375]\n",
      "[1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Confusion matrix : \n",
      " [[ 12  13]\n",
      " [167 319]]\n",
      "\n",
      "True positive : 12\n",
      "False negative : 13\n",
      "False positive : 167\n",
      "True negative : 319\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.07      0.48      0.12        25\n",
      "           0       0.96      0.66      0.78       486\n",
      "\n",
      "    accuracy                           0.65       511\n",
      "   macro avg       0.51      0.57      0.45       511\n",
      "weighted avg       0.92      0.65      0.75       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 64.77  %\n",
      "Akurasi fold ini adalah : 64.77  %\n",
      "===========================================================\n",
      "===========================================================\n",
      "tanpa smote\n",
      "Confusion matrix : \n",
      " [[  0  25]\n",
      " [ 13 473]]\n",
      "\n",
      "True positive : 0\n",
      "False negative : 25\n",
      "False positive : 13\n",
      "True negative : 473\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        25\n",
      "           0       0.95      0.97      0.96       486\n",
      "\n",
      "    accuracy                           0.93       511\n",
      "   macro avg       0.47      0.49      0.48       511\n",
      "weighted avg       0.90      0.93      0.91       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 92.56  %\n",
      "Akurasi fold ini adalah : 92.56  %\n",
      "===========================================================\n",
      "fold ke- 4\n",
      "4599\n",
      "511\n",
      "[4375 4375]\n",
      "[0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Confusion matrix : \n",
      " [[ 13  12]\n",
      " [156 330]]\n",
      "\n",
      "True positive : 13\n",
      "False negative : 12\n",
      "False positive : 156\n",
      "True negative : 330\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.08      0.52      0.13        25\n",
      "           0       0.96      0.68      0.80       486\n",
      "\n",
      "    accuracy                           0.67       511\n",
      "   macro avg       0.52      0.60      0.47       511\n",
      "weighted avg       0.92      0.67      0.76       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 67.12  %\n",
      "Akurasi fold ini adalah : 67.12  %\n",
      "===========================================================\n",
      "===========================================================\n",
      "tanpa smote\n",
      "Confusion matrix : \n",
      " [[  0  25]\n",
      " [  9 477]]\n",
      "\n",
      "True positive : 0\n",
      "False negative : 25\n",
      "False positive : 9\n",
      "True negative : 477\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        25\n",
      "           0       0.95      0.98      0.97       486\n",
      "\n",
      "    accuracy                           0.93       511\n",
      "   macro avg       0.48      0.49      0.48       511\n",
      "weighted avg       0.90      0.93      0.92       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 93.35  %\n",
      "Akurasi fold ini adalah : 93.35  %\n",
      "===========================================================\n",
      "fold ke- 5\n",
      "4599\n",
      "511\n",
      "[4375 4375]\n",
      "[0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Confusion matrix : \n",
      " [[ 10  15]\n",
      " [160 326]]\n",
      "\n",
      "True positive : 10\n",
      "False negative : 15\n",
      "False positive : 160\n",
      "True negative : 326\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.06      0.40      0.10        25\n",
      "           0       0.96      0.67      0.79       486\n",
      "\n",
      "    accuracy                           0.66       511\n",
      "   macro avg       0.51      0.54      0.45       511\n",
      "weighted avg       0.91      0.66      0.75       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 65.75  %\n",
      "Akurasi fold ini adalah : 65.75  %\n",
      "===========================================================\n",
      "===========================================================\n",
      "tanpa smote\n",
      "Confusion matrix : \n",
      " [[  3  22]\n",
      " [  8 478]]\n",
      "\n",
      "True positive : 3\n",
      "False negative : 22\n",
      "False positive : 8\n",
      "True negative : 478\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.12      0.17        25\n",
      "           0       0.96      0.98      0.97       486\n",
      "\n",
      "    accuracy                           0.94       511\n",
      "   macro avg       0.61      0.55      0.57       511\n",
      "weighted avg       0.92      0.94      0.93       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 94.13  %\n",
      "Akurasi fold ini adalah : 94.13  %\n",
      "===========================================================\n",
      "fold ke- 6\n",
      "4599\n",
      "511\n",
      "[4375 4375]\n",
      "[0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Confusion matrix : \n",
      " [[ 11  14]\n",
      " [150 336]]\n",
      "\n",
      "True positive : 11\n",
      "False negative : 14\n",
      "False positive : 150\n",
      "True negative : 336\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.07      0.44      0.12        25\n",
      "           0       0.96      0.69      0.80       486\n",
      "\n",
      "    accuracy                           0.68       511\n",
      "   macro avg       0.51      0.57      0.46       511\n",
      "weighted avg       0.92      0.68      0.77       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 67.91  %\n",
      "Akurasi fold ini adalah : 67.91  %\n",
      "===========================================================\n",
      "===========================================================\n",
      "tanpa smote\n",
      "Confusion matrix : \n",
      " [[  3  22]\n",
      " [ 13 473]]\n",
      "\n",
      "True positive : 3\n",
      "False negative : 22\n",
      "False positive : 13\n",
      "True negative : 473\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.19      0.12      0.15        25\n",
      "           0       0.96      0.97      0.96       486\n",
      "\n",
      "    accuracy                           0.93       511\n",
      "   macro avg       0.57      0.55      0.56       511\n",
      "weighted avg       0.92      0.93      0.92       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 93.15  %\n",
      "Akurasi fold ini adalah : 93.15  %\n",
      "===========================================================\n",
      "fold ke- 7\n",
      "4599\n",
      "511\n",
      "[4375 4375]\n",
      "[1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Confusion matrix : \n",
      " [[ 16   9]\n",
      " [159 327]]\n",
      "\n",
      "True positive : 16\n",
      "False negative : 9\n",
      "False positive : 159\n",
      "True negative : 327\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.64      0.16        25\n",
      "           0       0.97      0.67      0.80       486\n",
      "\n",
      "    accuracy                           0.67       511\n",
      "   macro avg       0.53      0.66      0.48       511\n",
      "weighted avg       0.93      0.67      0.76       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 67.12  %\n",
      "Akurasi fold ini adalah : 67.12  %\n",
      "===========================================================\n",
      "===========================================================\n",
      "tanpa smote\n",
      "Confusion matrix : \n",
      " [[  3  22]\n",
      " [  8 478]]\n",
      "\n",
      "True positive : 3\n",
      "False negative : 22\n",
      "False positive : 8\n",
      "True negative : 478\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.12      0.17        25\n",
      "           0       0.96      0.98      0.97       486\n",
      "\n",
      "    accuracy                           0.94       511\n",
      "   macro avg       0.61      0.55      0.57       511\n",
      "weighted avg       0.92      0.94      0.93       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 94.13  %\n",
      "Akurasi fold ini adalah : 94.13  %\n",
      "===========================================================\n",
      "fold ke- 8\n",
      "4599\n",
      "511\n",
      "[4375 4375]\n",
      "[0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Confusion matrix : \n",
      " [[ 16   9]\n",
      " [143 343]]\n",
      "\n",
      "True positive : 16\n",
      "False negative : 9\n",
      "False positive : 143\n",
      "True negative : 343\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.10      0.64      0.17        25\n",
      "           0       0.97      0.71      0.82       486\n",
      "\n",
      "    accuracy                           0.70       511\n",
      "   macro avg       0.54      0.67      0.50       511\n",
      "weighted avg       0.93      0.70      0.79       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 70.25  %\n",
      "Akurasi fold ini adalah : 70.25  %\n",
      "===========================================================\n",
      "===========================================================\n",
      "tanpa smote\n",
      "Confusion matrix : \n",
      " [[  1  24]\n",
      " [  9 477]]\n",
      "\n",
      "True positive : 1\n",
      "False negative : 24\n",
      "False positive : 9\n",
      "True negative : 477\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.10      0.04      0.06        25\n",
      "           0       0.95      0.98      0.97       486\n",
      "\n",
      "    accuracy                           0.94       511\n",
      "   macro avg       0.53      0.51      0.51       511\n",
      "weighted avg       0.91      0.94      0.92       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 93.54  %\n",
      "Akurasi fold ini adalah : 93.54  %\n",
      "===========================================================\n",
      "fold ke- 9\n",
      "4599\n",
      "511\n",
      "[4375 4375]\n",
      "[1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Confusion matrix : \n",
      " [[ 11  14]\n",
      " [133 353]]\n",
      "\n",
      "True positive : 11\n",
      "False negative : 14\n",
      "False positive : 133\n",
      "True negative : 353\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.08      0.44      0.13        25\n",
      "           0       0.96      0.73      0.83       486\n",
      "\n",
      "    accuracy                           0.71       511\n",
      "   macro avg       0.52      0.58      0.48       511\n",
      "weighted avg       0.92      0.71      0.79       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 71.23  %\n",
      "Akurasi fold ini adalah : 71.23  %\n",
      "===========================================================\n",
      "===========================================================\n",
      "tanpa smote\n",
      "Confusion matrix : \n",
      " [[  1  24]\n",
      " [  8 478]]\n",
      "\n",
      "True positive : 1\n",
      "False negative : 24\n",
      "False positive : 8\n",
      "True negative : 478\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.11      0.04      0.06        25\n",
      "           0       0.95      0.98      0.97       486\n",
      "\n",
      "    accuracy                           0.94       511\n",
      "   macro avg       0.53      0.51      0.51       511\n",
      "weighted avg       0.91      0.94      0.92       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 93.74  %\n",
      "Akurasi fold ini adalah : 93.74  %\n",
      "===========================================================\n",
      "fold ke- 10\n",
      "4599\n",
      "511\n",
      "[4374 4374]\n",
      "[0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1]\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Confusion matrix : \n",
      " [[ 17   7]\n",
      " [161 326]]\n",
      "\n",
      "True positive : 17\n",
      "False negative : 7\n",
      "False positive : 161\n",
      "True negative : 326\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.10      0.71      0.17        24\n",
      "           0       0.98      0.67      0.80       487\n",
      "\n",
      "    accuracy                           0.67       511\n",
      "   macro avg       0.54      0.69      0.48       511\n",
      "weighted avg       0.94      0.67      0.77       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 67.12  %\n",
      "Akurasi fold ini adalah : 67.12  %\n",
      "===========================================================\n",
      "===========================================================\n",
      "tanpa smote\n",
      "Confusion matrix : \n",
      " [[  2  22]\n",
      " [  5 482]]\n",
      "\n",
      "True positive : 2\n",
      "False negative : 22\n",
      "False positive : 5\n",
      "True negative : 482\n",
      "\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.08      0.13        24\n",
      "           0       0.96      0.99      0.97       487\n",
      "\n",
      "    accuracy                           0.95       511\n",
      "   macro avg       0.62      0.54      0.55       511\n",
      "weighted avg       0.92      0.95      0.93       511\n",
      "\n",
      "\n",
      "Akurasi fold ini adalah : 94.72  %\n",
      "Akurasi fold ini adalah : 94.72  %\n",
      "===========================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "c=1\n",
    "ak=[]\n",
    "aks=[]\n",
    "sm = SMOTE(random_state=42)\n",
    "skf= StratifiedKFold(n_splits=10)\n",
    "for train_id, test_id in skf.split(x_data, y_data):\n",
    "    print(\"fold ke-\",c)\n",
    "    print(len(train_id))\n",
    "    print(len(test_id))\n",
    "    x_train, y_train= x_data[train_id], y_data[train_id]\n",
    "    x_res, y_res = sm.fit_resample(x_train, y_train)\n",
    "    print(np.bincount(y_res))\n",
    "    x_test, y_test = x_data[test_id], y_data[test_id]\n",
    "\n",
    "    tree2 = C45(attrNames=[\"gender\",\"age\",\"hypertension\",\"heart_disease\",\"ever_married\",\"work_type\",\"Residence_type\",\"bmi\",\"avg_glucose_level\",\"smoking_status\"])\n",
    "\n",
    "    tree = C45(attrNames=[\"gender\",\"age\",\"hypertension\",\"heart_disease\",\"ever_married\",\"work_type\",\"Residence_type\",\"bmi\",\"avg_glucose_level\",\"smoking_status\"])\n",
    "    tree.fit(x_res,y_res)\n",
    "    tree2.fit(x_train,y_train)\n",
    "    # tree.printTree()\n",
    "    y_pred = tree.predict(x_test)\n",
    "    print(y_pred)\n",
    "\n",
    "    y_pred2 = tree2.predict(x_test)\n",
    "    print(y_pred2)\n",
    "    matrix = confusion_matrix(y_test, y_pred, labels=[1,0])\n",
    "    print('Confusion matrix : \\n',matrix)\n",
    "    print(\"\")\n",
    "\n",
    "    # outcome values order in sklearn\n",
    "    tp, fn, fp, tn = confusion_matrix(y_test, y_pred,labels=[1,0]).reshape(-1)\n",
    "    print(\"True positive :\", tp)\n",
    "    print(\"False negative :\", fn)\n",
    "    print(\"False positive :\", fp)\n",
    "    print(\"True negative :\", tn)\n",
    "    print(\"\")\n",
    "\n",
    "    # classification report for precision, recall f1-score and accuracy\n",
    "    matrix = classification_report(y_test, y_pred,labels=[1,0])\n",
    "    print('Classification report : \\n',matrix)\n",
    "    print(\"\")\n",
    "\n",
    "    #akurasi\n",
    "    accuracy = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "    print(\"Akurasi fold ini adalah :\", accuracy, \" %\")\n",
    "    accuracy2 = round(((tp+tn)/(tp+fn+fp+tn)*100), 2)\n",
    "    aks.append(accuracy2)\n",
    "    print(\"Akurasi fold ini adalah :\", accuracy2, \" %\")\n",
    "    print(\"===========================================================\")\n",
    "    print(\"===========================================================\")\n",
    "    print(\"tanpa smote\")\n",
    "    matrix2 = confusion_matrix(y_test, y_pred2, labels=[1,0])\n",
    "    print('Confusion matrix : \\n',matrix2)\n",
    "    print(\"\")\n",
    "\n",
    "    # outcome values order in sklearn\n",
    "    tp2, fn2, fp2, tn2 = confusion_matrix(y_test, y_pred2,labels=[1,0]).reshape(-1)\n",
    "    print(\"True positive :\", tp2)\n",
    "    print(\"False negative :\", fn2)\n",
    "    print(\"False positive :\", fp2)\n",
    "    print(\"True negative :\", tn2)\n",
    "    print(\"\")\n",
    "\n",
    "    # classification report for precision, recall f1-score and accuracy\n",
    "    matrix2 = classification_report(y_test, y_pred2,labels=[1,0])\n",
    "    print('Classification report : \\n',matrix2)\n",
    "    print(\"\")\n",
    "\n",
    "    #akurasi\n",
    "    accuracy3 = round(accuracy_score(y_test, y_pred2)*100, 2)\n",
    "    print(\"Akurasi fold ini adalah :\", accuracy3, \" %\")\n",
    "    accuracy4 = round(((tp2+tn2)/(tp2+fn2+fp2+tn2)*100), 2)\n",
    "    ak.append(accuracy4)\n",
    "    print(\"Akurasi fold ini adalah :\", accuracy4, \" %\")\n",
    "    print(\"===========================================================\")\n",
    "    \n",
    "    # print(len(x_train))\n",
    "    # print(len(x_test))\n",
    "    # print(\"jumlah label train positif\",len(np.where(y_train == 1)))\n",
    "    # print(\"jumlah label train negatif\",len(np.where(y_train == 0)))\n",
    "    c+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45b33d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k = [\"k\"+str(i+1) for i in range(10)]\n",
    "# line 1 points\n",
    "# plotting the line 1 points\n",
    "plt.plot(k, ak,aks, label = \"c45\", marker='o', markerfacecolor='blue', markersize=5)\n",
    "\n",
    "barWidth = 0.25\n",
    "fig = plt.subplots(figsize =(12, 8))\n",
    "br1 = np.arange(len(ak))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "# Make the plot\n",
    "plt.bar(br1, ak, color ='r', width = barWidth,\n",
    "        edgecolor ='grey', label ='akurasi tanpa smote')\n",
    "plt.bar(br2, aks, color ='g', width = barWidth,\n",
    "        edgecolor ='grey', label ='akurasi smote')\n",
    "\n",
    "# Adding Xticks\n",
    "plt.xlabel('tingkat akurasi', fontweight ='bold', fontsize = 15)\n",
    "plt.ylabel('fold ke', fontweight ='bold', fontsize = 15)\n",
    "\n",
    "\n",
    "# naming the x axis\n",
    "plt.xlabel('Fold')\n",
    "# naming the y axis\n",
    "plt.ylabel('Akurasi')\n",
    "# giving a title to my graph\n",
    "plt.title('Perbandingan akurasi')\n",
    " \n",
    "# show a legend on the plot\n",
    "plt.legend()\n",
    " \n",
    "# function to show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed99d71367fcbfe9963a7f3a9c951c1f51694b84bd5e0f32527a3b47ddf21a02"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
